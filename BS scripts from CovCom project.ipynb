{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Copy of Company Details (Google).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "fe44fef87f92f48a3a32707d0df204585f471652bc0ce87358a3ce712bc24db0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# download libraries\r\n",
        "!pip install --upgrade pip\r\n",
        "!pip install bs4\r\n",
        "!pip install pandas\r\n",
        "!pip install requests\r\n",
        "!pip install numpy\r\n",
        "!pip install urllib3\r\n",
        "!pip install phonenumbers\r\n",
        "!pip install validate_email"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# scraping multiple timestamps of govt list of pcr providers (obtaining comany name, website, number & email)\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import pandas as pd\r\n",
        "import requests\r\n",
        "from urllib.parse import urlparse\r\n",
        "import numpy as np\r\n",
        "import phonenumbers\r\n",
        "\r\n",
        "urls = [\r\n",
        "    'https://www.find-travel-test-provider.service.gov.uk/test-type/amber', \r\n",
        "    'https://web.archive.org/web/20210519121145/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210520140910/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210526072031/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210529103556/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210531150239/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210604100539/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210618121419/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210626230824/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210629104343/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210701142411/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210708123655/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210713165043/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210729180818/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210808132243/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210811073050/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210812113842/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210817114915/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210818174329/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210823032256/https://www.find-travel-test-provider.service.gov.uk/test-type/amber',\r\n",
        "    'https://web.archive.org/web/20210824065330/https://www.find-travel-test-provider.service.gov.uk/test-type/amber'\r\n",
        "]\r\n",
        "\r\n",
        "provider_details = pd.DataFrame(columns=['company_name','company_link', 'company_number', 'company_email'])\r\n",
        "\r\n",
        "for url in urls:\r\n",
        "    print(url)\r\n",
        "    # scrape gvmt test provider site table\r\n",
        "    page = requests.get(url)\r\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')\r\n",
        "    providers_table = soup.find('table', {'class', 'govuk-table'}).find('tbody')\r\n",
        "\r\n",
        "    url_provider_details = pd.DataFrame(columns=['company_name', 'company_link', 'company_number', 'company_email'])\r\n",
        "    for row in providers_table.find_all('tr'):\r\n",
        "        # test provider saved in cell with id 'provider'\r\n",
        "        provider = row.find(id='provider').find('a')\r\n",
        "        name = provider.get_text().rstrip().lower()\r\n",
        "        link = provider['href']\r\n",
        "    \r\n",
        "        # test provider number and email saved in only cell(s) with no id\r\n",
        "        number_email = row.find_all('td', id=None)\r\n",
        "        \r\n",
        "        # remove web archive prefix from wayback machine\r\n",
        "        link = link[43:] if 'web.archive.org' in link else link\r\n",
        "\r\n",
        "        # old format stores number and email in separate cells\r\n",
        "        # new format stores number and email in same cell\r\n",
        "        if len(number_email) == 1:\r\n",
        "            number_email = number_email[0].find_all('a')\r\n",
        "        number = str(number_email[0].get_text())\r\n",
        "        email = number_email[1].get_text()\r\n",
        "        \r\n",
        "        # apply standard format to numbers, emails and links\r\n",
        "        if number and len(number) >= 10:\r\n",
        "            number = ' '.join(number.rstrip().split())\r\n",
        "            number = phonenumbers.format_number(phonenumbers.parse(number, 'GB'), phonenumbers.PhoneNumberFormat.INTERNATIONAL)\r\n",
        "        else:\r\n",
        "            number = np.nan \r\n",
        "\r\n",
        "        if email:\r\n",
        "            email = str(email).lower()\r\n",
        "\r\n",
        "        if link:\r\n",
        "            link = urlparse(link.lower()).netloc\r\n",
        "\r\n",
        "        url_provider_details = url_provider_details.append({\r\n",
        "            'company_name': name,\r\n",
        "            'company_link': link,\r\n",
        "            'company_number': number,\r\n",
        "            'company_email': email\r\n",
        "        }, ignore_index=True)\r\n",
        "\r\n",
        "    provider_details = pd.merge(\r\n",
        "        provider_details, \r\n",
        "        url_provider_details, \r\n",
        "        how=\"outer\", \r\n",
        "        on=['company_name','company_link','company_number','company_email']\r\n",
        "    )\r\n",
        "\r\n",
        "provider_details.to_csv('datasets/provider_details.csv')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ff0gsQpq9r",
        "outputId": "922023be-7a57-4a15-8bf1-1d7426b7feb7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# group all numbers, emails, and links for each company together\r\n",
        "grouped_details = pd.DataFrame(columns=['company_name'])\r\n",
        "provider_details = pd.read_csv('datasets/provider_details.csv')\r\n",
        "\r\n",
        "for category in ['company_number', 'company_email', 'company_link']:\r\n",
        "    category_details = provider_details[['company_name', category]].drop_duplicates()\r\n",
        "    df = (category_details.set_index(['company_name', category_details.groupby('company_name').cumcount()])[category]\r\n",
        "            .unstack(fill_value='')\r\n",
        "            .add_prefix(category+'_')\r\n",
        "            .reset_index())\r\n",
        "\r\n",
        "    grouped_details = pd.merge(grouped_details, df, how='outer',on=['company_name'])\r\n",
        "\r\n",
        "grouped_details.to_csv('datasets/grouped_details.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "RqV0oOlhqP3x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import phonenumbers\r\n",
        "\r\n",
        "# validate scraped phone numbers\r\n",
        "grouped_details = pd.read_csv('datasets/grouped_details.csv')\r\n",
        "phone_cols = [x for x in grouped_details.columns if 'company_number' in x]\r\n",
        "\r\n",
        "def check_number(x):\r\n",
        "    results = []\r\n",
        "    for cell in x:\r\n",
        "        if pd.isna(cell) or len(str(cell)) < 9:\r\n",
        "            results.append('')\r\n",
        "        else:\r\n",
        "            number = phonenumbers.parse(cell,'GB')\r\n",
        "            valid = phonenumbers.is_valid_number(number)\r\n",
        "            results.append(valid)\r\n",
        "    return results\r\n",
        "\r\n",
        "phone_details = grouped_details[phone_cols]\r\n",
        "phone_validated = phone_details.apply(check_number)\r\n",
        "phone_validated['company_name'] = grouped_details['company_name']\r\n",
        "\r\n",
        "phone_validated.to_csv('datasets/phone_validation.csv')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from validate_email import validate_email\r\n",
        "\r\n",
        "# validate scraped email addresses\r\n",
        "grouped_details = pd.read_csv('datasets/grouped_details.csv')\r\n",
        "email_cols = [x for x in grouped_details.columns if 'company_email' in x]\r\n",
        "\r\n",
        "def check_email(x):\r\n",
        "    results = []\r\n",
        "    for cell in x:\r\n",
        "        if not cell:\r\n",
        "            results.append('')\r\n",
        "        else:\r\n",
        "            valid = validate_email(email=str(cell))\r\n",
        "            results.append(valid)\r\n",
        "\r\n",
        "email_details = grouped_details[email_cols]\r\n",
        "email_validated = email_details.apply(check_email)\r\n",
        "email_validated['company_name'] = grouped_details['company_name']\r\n",
        "\r\n",
        "email_validated.to_csv('datasets/email_validation.csv')\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# obtaining trustpilot links\r\n",
        "grouped_details = pd.read_csv('datasets/grouped_details.csv')\r\n",
        "link_cols = [x for x in grouped_details.columns if 'company_link' in x]\r\n",
        "\r\n",
        "def check_trustpilot(x):\r\n",
        "    results = []\r\n",
        "    for cell in x:\r\n",
        "        if pd.isna(cell) or not cell:\r\n",
        "            results.append('')\r\n",
        "        else:\r\n",
        "            print(cell)\r\n",
        "            page = requests.get(\"https://uk.trustpilot.com/review/\"+cell)\r\n",
        "            soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
        "            score = soup.find('p', {'class', 'header_trustscore'})\r\n",
        "                \r\n",
        "            results.append(score.get_text() if score else '')\r\n",
        "\r\n",
        "    return results\r\n",
        "\r\n",
        "\r\n",
        "link_details = grouped_details[link_cols]\r\n",
        "trustpilot_scores = link_details.apply(check_trustpilot) \r\n",
        "trustpilot_scores['company_name'] = grouped_details['company_name']\r\n",
        "\r\n",
        "trustpilot_scores.to_csv('datasets/trustpilot_scores.csv')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# match registered CH companies \r\n",
        "import requests\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import pandas as pd\r\n",
        "from fuzzywuzzy.fuzz import partial_ratio\r\n",
        "\r\n",
        "api_key = '3511f785-bc60-40b3-b697-36bedb63c848'\r\n",
        "\r\n",
        "grouped_details = pd.read_csv('datasets/grouped_details.csv')\r\n",
        "matched_companies = pd.DataFrame(columns=['company_name', 'registered_name'])\r\n",
        "matched_companies['company_name'] = grouped_details['company_name']\r\n",
        "\r\n",
        "matched = []\r\n",
        "for company in grouped_details['company_name']:\r\n",
        "    match = ''\r\n",
        "\r\n",
        "    company = company.lower()\r\n",
        "    response = requests.get(\r\n",
        "        'https://api.company-information.service.gov.uk/search?items_per_page=1&q='+'+'.join(company.split()), \r\n",
        "        auth=(api_key, '')\r\n",
        "    )\r\n",
        "\r\n",
        "    if response:\r\n",
        "        response_json = response.json()\r\n",
        "        if response_json['total_results'] > 1:\r\n",
        "            company_found = response.json()['items'][0]['title'].lower()\r\n",
        "            \r\n",
        "            if partial_ratio(company_found, company) >= 80:\r\n",
        "                match = company_found\r\n",
        "        \r\n",
        "    matched.append(match)\r\n",
        "\r\n",
        "matched_companies['registered_name'] = matched\r\n",
        "matched_companies.to_csv('./datasets/ch_matched.csv')"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}