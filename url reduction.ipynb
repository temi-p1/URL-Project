{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.bbc.co.uk', 'https://www.amazon.co.uk', 'https://www.amazon.co.uk']\n"
     ]
    }
   ],
   "source": [
    "# REMOVING URLS WHICH APPEAR IN EXTERNAL LIST (E.G. REDLIST OR WHITELIST)\n",
    "\n",
    "set1 = urls = [\n",
    "    \"https://www.bbc.co.uk/news\",\n",
    "    \"https://www.bbc.co.uk\",\n",
    "    \"https://www.amazon.co.uk\",\n",
    "    \"https://www.amazon.co.uk\"\n",
    "]\n",
    "set2 = [\"https://www.bbc.co.uk/news\"]\n",
    "\n",
    "# takes two arrays of strings as input\n",
    "# removes any elements of urlSet that match any elements of externalSet\n",
    "def urlReduce(urlSet,externalSet):\n",
    "    newSet = []\n",
    "    for url in urlSet:\n",
    "        indicator = 0\n",
    "        for item in externalSet:\n",
    "            if(url == item):\n",
    "                indicator = 1\n",
    "        if(indicator == 0):\n",
    "            newSet.append(url)\n",
    "    return newSet\n",
    "\n",
    "set3 = urlReduce(set1,set2)\n",
    "print(set3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.bbc.co.uk/news', 'https://www.bbc.co.uk', 'https://www.amazon.co.uk']\n"
     ]
    }
   ],
   "source": [
    "# DE-DUPLICATION\n",
    "set4 = list(dict.fromkeys(set1))\n",
    "print(set4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bbc.co.uk', 'bbc.co.uk', 'amazon.co.uk', 'amazon.co.uk']\n"
     ]
    }
   ],
   "source": [
    "# GET DOMAIN NAMES (for partial url matching/grouping by domain)\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def getDomain(urlSet):\n",
    "    newSet = []\n",
    "    for url in urlSet:\n",
    "        site = urlparse(url).netloc\n",
    "        domain = ('.'.join(site.split('.')[1:]))\n",
    "        newSet.append(domain)\n",
    "    return newSet\n",
    "\n",
    "set5 = getDomain(set1)\n",
    "print(set5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e278ca4e9a2ae999502812da3aa9042213e3ce53c46b5f0452fc22ced78fb5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
