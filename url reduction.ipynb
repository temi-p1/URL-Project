{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.bbc.co.uk', 'https://www.amazon.co.uk', 'https://www.amazon.co.uk']\n"
     ]
    }
   ],
   "source": [
    "# removing urls which appear in list (e.g. redlist or whitelist)\n",
    "\n",
    "set1 = urls = [\n",
    "    \"https://www.bbc.co.uk/news\",\n",
    "    \"https://www.bbc.co.uk\",\n",
    "    \"https://www.amazon.co.uk\",\n",
    "    \"https://www.amazon.co.uk\"\n",
    "]\n",
    "set2 = [\"https://www.bbc.co.uk/news\"]\n",
    "\n",
    "# takes two arrays of strings as input\n",
    "# removes any elements of urlSet that match any elements of externalSet\n",
    "def urlReduce(urlSet,externalSet):\n",
    "    newSet = []\n",
    "    for url in urlSet:\n",
    "        indicator = 0\n",
    "        for item in externalSet:\n",
    "            if(url == item):\n",
    "                indicator = 1\n",
    "        if(indicator == 0):\n",
    "            newSet.append(url)\n",
    "    return newSet\n",
    "\n",
    "set3 = urlReduce(set1,set2)\n",
    "print(set3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.bbc.co.uk/news', 'https://www.bbc.co.uk', 'https://www.amazon.co.uk']\n"
     ]
    }
   ],
   "source": [
    "# delete duplicates\n",
    "set4 = list(dict.fromkeys(set1))\n",
    "print(set4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          url    dup first of dup\n",
      "0  https://www.bbc.co.uk/news  False          N/A\n",
      "1       https://www.bbc.co.uk  False          N/A\n",
      "2    https://www.amazon.co.uk   True            T\n",
      "3    https://www.amazon.co.uk   True            F\n"
     ]
    }
   ],
   "source": [
    "# flag duplicates\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'url':set1})\n",
    "df['dup'] = df.duplicated(keep=False)\n",
    "#print(df)\n",
    "\n",
    "# flag first duplicates\n",
    "first = [0]*len(df.index)\n",
    "for i in range(len(df.index)):\n",
    "    if (df['dup'][i] == True):\n",
    "        if df['url'][i] in set(df['url'][0:i]):\n",
    "            first[i] = 'F'\n",
    "        else:\n",
    "            first[i] = 'T'\n",
    "    else:\n",
    "        first[i] = 'N/A'\n",
    "df['first of dup'] = first\n",
    "\n",
    "print(df)\n",
    "\n",
    "# It may be useful to retain the times a person has visited one website (if there's been multiple visits)\n",
    "# Instead of deleting all rows in the dataframe which contain duplicated URLs (and the times visited), \n",
    "# we could retain those rows but just duplicate the extracted data (screenshots etc.) to save time/computational work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bbc.co.uk', 'bbc.co.uk', 'amazon.co.uk', 'amazon.co.uk']\n"
     ]
    }
   ],
   "source": [
    "# get domain names (for partial url matching/grouping by domain)\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def getDomain(urlSet):\n",
    "    newSet = []\n",
    "    for url in urlSet:\n",
    "        site = urlparse(url).netloc\n",
    "        domain = ('.'.join(site.split('.')[1:]))\n",
    "        newSet.append(domain)\n",
    "    return newSet\n",
    "\n",
    "set5 = getDomain(set1)\n",
    "print(set5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e278ca4e9a2ae999502812da3aa9042213e3ce53c46b5f0452fc22ced78fb5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
