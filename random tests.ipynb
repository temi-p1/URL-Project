{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup get visible text from webpages (unreliable)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "\n",
    "# indicator of whether element is visible based on tag\n",
    "# this is just a guess and is not consistent across all sites\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# func to get text given html\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "urls = ['http://www.nytimes.com/2009/12/21/us/21storm.html','https://www.youtube.com/']\n",
    "\n",
    "# overall func to get text given list of urls\n",
    "def getText1(urls):\n",
    "    texts = []\n",
    "    for url in urls:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "        texts.append(text_from_html(html))\n",
    "    return texts\n",
    "\n",
    "print(getText1(urls)[0]) # works well for news site\n",
    "print(getText1(urls)[1]) # works terribly for youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup get visible text from webpages (written more efficiently) (unreliable)\n",
    "\n",
    "urls = ['http://www.nytimes.com/2009/12/21/us/21storm.html','https://www.youtube.com/']\n",
    "\n",
    "def getText2(urls):\n",
    "    texts = []\n",
    "    for url in urls:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(html)\n",
    "        [s.extract() for s in soup(['style', 'script', '[document]', 'head', 'title'])]\n",
    "        texts.append(soup.getText())\n",
    "    return texts\n",
    "\n",
    "print(getText2(urls))\n",
    "# extracted text isnt as nice as getText1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium get text\n",
    "from selenium import webdriver\n",
    "exec_path = r\"C:\\Users\\JoshAlder\\OneDrive - Principle One\\Documents\\VS Code\\URLs Project New\\Rando\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(executable_path=exec_path)\n",
    "driver.get(\"https://www.bbc.co.uk/news/business-58830955\")\n",
    "driver.get('https://www.youtube.com/')\n",
    "el = driver.find_element_by_tag_name('body').text\n",
    "print(el)\n",
    "# driver.close()\n",
    "# This script cant get past sign in pop up whereas BS seems to be able to (NYTimes Article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapy (faster than other libraries)\n",
    "# selectors - still need to specify tags & locations in HTML?\n",
    "import scrapy\n",
    "\n",
    "class TestSpider(scrapy.Spider):\n",
    "    name = 'test'\n",
    "    start_urls = [\"https://www.bbc.co.uk/news/business-58830955\"]\n",
    "\n",
    "    def parse(self,response):\n",
    "        links = response.xpath('//body//text()')\n",
    "        html = \"\"\n",
    "        for link in links:\n",
    "            url = links.get()\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inscriptis get text - works well for lots of sites but struggles with youtube for some reason\n",
    "import urllib.request \n",
    "from inscriptis import get_text \n",
    " \n",
    "urls = [\"https://www.amazon.co.uk/introducing-fire-tv-stick-lite-with-alexa-voice-remote-lite-no-tv-controls-2020-release/dp/B07ZZW7QCM/?_encoding=UTF8&pd_rd_w=momYP&pf_rd_p=7b33cd3c-1a87-4db8-9f31-ba1adc449805&pf_rd_r=V3TTH21TYKK6REAYQ6TR&pd_rd_r=bc8c40c9-546b-4c63-8b4a-29fd04e2f958&pd_rd_wg=06pzc&ref_=pd_gw_unk\",\"https://www.bbc.co.uk/news/business-58830955\"]\n",
    "html = urllib.request.urlopen(urls[0]).read().decode('utf-8')\n",
    "text = get_text(html)\n",
    "\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloudscraper (can apparently get around protection? particularly cloudflare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google API website categorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Meta - Selenium/BS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTube pop-up closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tor URL processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL prioritisation and filtering\n",
    "# time and no. visits will be given in the history excel document obtained by police from devices"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e278ca4e9a2ae999502812da3aa9042213e3ce53c46b5f0452fc22ced78fb5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
